{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fewer-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' проигрывает музыку '''\n",
    "playsound(\"C:\\\\Users\\\\HP\\\\Desktop\\\\Kursovaya\\\\music4kurs\\\\MoonSonat.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thousand-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legislative-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'C:\\\\Users\\\\HP\\\\Desktop\\\\Kursovaya\\\\ABC.txt';\n",
    "with open(file,'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "overall-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "song = text.split('\\n\\n')\n",
    "with open (file,\"w\") as f:\n",
    "    f.write(''.join(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indonesian-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "# набор симвлов \n",
    "vocab = set(text)\n",
    "\n",
    "# присваевает каждому уникальному символу индекс \n",
    "char_to_index = {char_: ind for ind, char_ in enumerate (vocab)} \n",
    "\n",
    "''' создает многомерный массив из уникальных символов\n",
    "ind_to_char = np.array(vocab) '''\n",
    "\n",
    "# создает массив индексов \n",
    "text_as_int = np.array([char_to_index[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nasty-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# временный массив символов\n",
    "a1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "damaged-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем символы из словаря в список\n",
    "for i in vocab:\n",
    "    a1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unlikely-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# превращаем список в массив\n",
    "ind_to_char = np.array(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "challenging-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "# размер тренировочного набора\n",
    "seq_length = 100\n",
    "\n",
    "step = 10\n",
    "\n",
    "# матрица  из объекта text_as_int (320x101)\n",
    "sequences = np.array([text_as_int[i:i+seq_length+1] for i in range(0, len(text_as_int)-seq_length-1,step)])\n",
    "\n",
    "#матрица из объекта  sequences без последнего элемента (320х100)\n",
    "input_text = np.array([seq[:-1] for seq in sequences])\n",
    "\n",
    "#матрица из объекта  sequences без первого жлемента (320х100)\n",
    "target_text = np.array([seq[1:] for seq in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "working-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chubby-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "#количество символов (55)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "historical-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 512)          28160     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100, 2048)         20979712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100, 55)           112695    \n",
      "=================================================================\n",
      "Total params: 21,120,567\n",
      "Trainable params: 21,120,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# размер выхода \n",
    "embedding_dim = 256*2\n",
    "# размерность выходного пространства\n",
    "rnn_units = 1024*2\n",
    "\n",
    "# входные данные типа int, количество 100, кортежи пусиые\n",
    "x = Input(shape=(seq_length,))\n",
    "\n",
    "# Сщставляет из х  вектор размера vocab_size, на выходе должен получится вектор размера embedding_dim, кортежи пустые \n",
    "e = Embedding(vocab_size, embedding_dim)(x)\n",
    "\n",
    "# Слой LSTM \n",
    "l = LSTM(rnn_units, return_sequences=True)(e)\n",
    "\n",
    "''' \n",
    "Dense: реализует операцию вывод=активация(dot(input, kernel) + bias), где\n",
    "активация поэлементная функция активации,\n",
    "kernel матрица весов слоя,\n",
    "bias вектор смещения, сформированный слоем\n",
    "\n",
    "Вход: размервыхода (vocab_size), функция активации (activation='softmax')\n",
    "\n",
    "softmax - это математическая функция, которая преобразует вектор чисел в вектор вероятностей,\n",
    "где вероятности каждого значения пропорциональны относительному масштабу каждого значения в векторе.\n",
    "\n",
    "'''\n",
    "d = Dense(vocab_size, activation='softmax')(l)\n",
    "\n",
    "''' \n",
    "Model: группирует слои в объект с функциями обучения и вывода\n",
    "Вход: inputs - из чего хотим получить\n",
    "outputs - что хотим получить\n",
    "'''\n",
    "model = Model(inputs=x, outputs=d)\n",
    "\n",
    "# печатает сводку о сети\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beginning-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Адам - это алгоритм оптимизации,который можно использоватьвместо классической процедуры стохастического градиентного спускадля\n",
    "итеративного обновления весов сети на основе обучающих данных.\n",
    "\n",
    "Стохастический градиентный спуск-оптимизационный алгоритм, отличающийся от обычного градиентного спуска тем, \n",
    "что градиент оптимизируемой функции считается на каждом шаге не как сумма градиентов от каждого элемента выборки, \n",
    "а как градиент от одного, случайно выбранного элемента.\n",
    "\n",
    "градиентный спуск -метод нахождения локального минимума или максимума функции с помощью движения вдоль градиента.\n",
    "'''\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accredited-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "compile - настраивает модель для обучения\n",
    "Вход: optimizer=Adam() - имя оптимизатора \n",
    "loss - имя целевой функции\n",
    "'''\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tutorial-edgar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 54s 17s/step - loss: 4.6633\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 50s 16s/step - loss: 3.6434\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 54s 17s/step - loss: 3.3952\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 59s 19s/step - loss: 3.3611\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 61s 19s/step - loss: 3.2963\n"
     ]
    }
   ],
   "source": [
    "#кличество эпох\n",
    "EP=5\n",
    "\n",
    "#количество образцов \n",
    "BS = 128\n",
    "\n",
    "'''\n",
    "fit: обучает модел для фиксированного количества эпох (итераций в наборе данных)\n",
    "Вход: input_text - входные данные, \n",
    "target_text - целевые данные\n",
    "batch_size - количество образцов на обновление градиентов\n",
    "epochs - количество эпох\n",
    "'''\n",
    "hist = model.fit(input_text, target_text, batch_size=BS, epochs=EP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "comprehensive-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, generation_length=100):\n",
    "    input_eval = np.array([char_to_index[s] for s in start_string])\n",
    "    xx = np.zeros((1, seq_length))\n",
    "    xx[0,-len(input_eval):] = input_eval[:]\n",
    "    text_generated = []\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(generation_length):\n",
    "        predictions = model.predict(xx)[0,-1] \n",
    "        predictions = predictions.astype(np.float64)\n",
    "        predictions = predictions/np.sum(predictions)    \n",
    "        predicted_id = np.argmax(np.random.multinomial(1, predictions))\n",
    "        xx[0,:-1] = xx[0,1:]\n",
    "        xx[0,-1] = predicted_id\n",
    "        text_generated.append([ind_to_char[predicted_id]]) \n",
    "        temp = [ ''.join(x) for x in text_generated ]\n",
    "\n",
    "    return (start_string + ''.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stylish-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_song = generate_text(model, \"A:\", generation_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "naked-gazette",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A:o2fF|Mfa!-\\n2!uCF!pi ,M e !u  AGw2= ,:z,!F_a 2Fez-s[r ,:2V  e,rucF|\"2w2Fc .-!  V ieir]Vda- sTpa[DdoG:22c:b]d-h-a -ro|cBr  o] -:orc-tpo-:| !  Aa-daicrDS|aCa -u|io:Aw|t|2w G.2 f adr F rTe | t 2ha/ 2w: aaB nm):gF=m)2|:e|2it-2  !  [  T|!aa :-CFei222t!Anma-  ]e e-[b( a aG|o- iul m\"- F|aV |,a Fi/Eh)AB2  :  Ga |-.|\\n 2|w2Gcr-a n ud rF:   |feFoV AA:2|rc:2]A\\na     A-ba !c|V c-c  ,  ,\\n f hA M , |)-,a=a,a-(o !w2 rAiGB a r2 V a|[!! r,eteu |r    )zeto2     : rp -r2G-\\nAe\\nib,-r|,hei:2| aAA|),(BtAa,:2rd-Ma- r -|A'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняет в текстовый файл\n",
    "with open('C:\\\\Users\\\\HP\\\\Desktop\\\\Kursovaya\\\\new_song.txt',\"w\") as f:\n",
    "    f.write(new_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "continental-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняет в adc файл\n",
    "with open('C:\\\\Users\\\\HP\\\\Desktop\\\\Kursovaya\\\\new_song.abc',\"w\") as f:\n",
    "    f.write(new_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-bride",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
